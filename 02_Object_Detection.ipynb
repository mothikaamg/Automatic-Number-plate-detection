{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4b5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3787a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mothikaa/ANPR/images/N192.xml</td>\n",
       "      <td>543</td>\n",
       "      <td>769</td>\n",
       "      <td>390</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mothikaa/ANPR/images/N149.xml</td>\n",
       "      <td>186</td>\n",
       "      <td>324</td>\n",
       "      <td>116</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mothikaa/ANPR/images/N100.xml</td>\n",
       "      <td>134</td>\n",
       "      <td>301</td>\n",
       "      <td>312</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mothikaa/ANPR/images/N116.xml</td>\n",
       "      <td>157</td>\n",
       "      <td>316</td>\n",
       "      <td>226</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mothikaa/ANPR/images/N57.xml</td>\n",
       "      <td>211</td>\n",
       "      <td>406</td>\n",
       "      <td>161</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filepath  xmin  xmax  ymin  ymax\n",
       "0  /home/mothikaa/ANPR/images/N192.xml   543   769   390   461\n",
       "1  /home/mothikaa/ANPR/images/N149.xml   186   324   116   148\n",
       "2  /home/mothikaa/ANPR/images/N100.xml   134   301   312   350\n",
       "3  /home/mothikaa/ANPR/images/N116.xml   157   316   226   278\n",
       "4   /home/mothikaa/ANPR/images/N57.xml   211   406   161   202"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8e8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fcd2f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mothikaa/ANPR/images/N192.xml'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = df['filepath'][0]\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b7fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilename(filename):\n",
    "    filename_image = xet.parse(filename).getroot().find('filename').text\n",
    "    filepath_image = os.path.join('/home/mothikaa/ANPR/images',filename_image)\n",
    "    return filepath_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d18536e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mothikaa/ANPR/images/N192.jpeg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getFilename(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04f5423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/mothikaa/ANPR/images/N192.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N149.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N100.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N116.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N57.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N206.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N199.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N123.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N78.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N66.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N90.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N148.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N150.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N126.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N173.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N9.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N5.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N68.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N4.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N225.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N140.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N122.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N132.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N232.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N187.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N74.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N144.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N108.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N179.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N95.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N28.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N145.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N107.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N154.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N130.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N240.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N30.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N133.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N138.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N193.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N92.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N8.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N49.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N63.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N18.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N113.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N162.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N152.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N170.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N82.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N177.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N124.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N200.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N236.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N94.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N227.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N204.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N202.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N153.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N59.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N218.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N70.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N104.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N158.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N219.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N86.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N62.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N50.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N156.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N147.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N176.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N155.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N64.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N84.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N141.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N142.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N128.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N6.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N237.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N73.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N109.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N17.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N221.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N213.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N127.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N3.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N217.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N43.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N106.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N189.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N167.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N72.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N36.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N205.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N247.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N164.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N201.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N234.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N171.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N229.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N137.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N195.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N56.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N118.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N121.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N214.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N165.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N91.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N222.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N163.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N160.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N119.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N24.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N186.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N183.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N215.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N184.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N1.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N185.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N69.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N238.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N244.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N35.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N89.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N51.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N211.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N33.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N175.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N67.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N37.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N81.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N11.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N207.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N239.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N32.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N208.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N22.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N188.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N20.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N2.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N241.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N61.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N111.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N246.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N216.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N134.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N112.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N242.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N212.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N181.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N42.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N190.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N99.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N97.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N19.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N31.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N54.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N139.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N178.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N174.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N169.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N52.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N168.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N105.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N45.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N79.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N14.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N224.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N114.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N210.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N191.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N135.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N23.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N44.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N136.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N198.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N120.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N231.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N117.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N166.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N21.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N203.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N103.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N196.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N38.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N129.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N15.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N27.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N197.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N110.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N88.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N223.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N47.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N12.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N209.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N220.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N226.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N53.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N102.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N46.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N7.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N16.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N151.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N248.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N233.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N75.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N58.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N235.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N34.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N172.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N93.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N77.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N96.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N48.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N85.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N245.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N40.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N101.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N80.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N65.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N25.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N230.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N143.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N131.jpeg',\n",
       " '/home/mothikaa/ANPR/images/N98.jpeg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = list(df['filepath'].apply(getFilename))\n",
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d6fbb",
   "metadata": {},
   "source": [
    "## Verify Image and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c14c09b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mothikaa/ANPR/images/N192.jpeg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = image_path[0]\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1592a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(file_path)\n",
    "cv2.rectangle(img,(543,390),(769,461),(0,255,0),3)\n",
    "cv2.namedWindow('example',cv2.WINDOW_AUTOSIZE)\n",
    "cv2.startWindowThread()\n",
    "cv2.imshow('example',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e36e1",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d363fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e97ce52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73f5787",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "output = []\n",
    "\n",
    "for ind in range(len(image_path)):\n",
    "    image = image_path[0]\n",
    "    img_arr = cv2.imread(image)\n",
    "    h,w,d = img_arr.shape\n",
    "\n",
    "    # Preprocessing\n",
    "    load_image = load_img(image,target_size=(224,224))\n",
    "    load_image_arr = img_to_array(load_image)\n",
    "    norm_load_image_arr = load_image_arr\n",
    "\n",
    "    #Normalization to labels\n",
    "    xmin,xmax,ymin,ymax = labels[ind]\n",
    "    nxmin,nxmax = xmin/w,xmax/w\n",
    "    nymin,nymax = ymin/h,ymax/h\n",
    "    label_norm = (nxmin,nxmax,nymin,nymax)\n",
    "    data.append(norm_load_image_arr)\n",
    "    output.append(label_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f16a6013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4344, 0.6152, 0.5547652916073968, 0.6557610241820768),\n",
       " (0.1488, 0.2592, 0.16500711237553342, 0.21052631578947367),\n",
       " (0.1072, 0.2408, 0.4438122332859175, 0.49786628733997157),\n",
       " (0.1256, 0.2528, 0.32147937411095306, 0.39544807965860596),\n",
       " (0.1688, 0.3248, 0.22901849217638692, 0.28733997155049784),\n",
       " (0.0968, 0.172, 0.17069701280227595, 0.20910384068278806),\n",
       " (0.036, 0.0896, 0.2930298719772404, 0.3627311522048364),\n",
       " (0.0088, 0.1968, 0.11095305832147938, 0.23470839260312945),\n",
       " (0.1168, 0.2416, 0.22759601706970128, 0.27880512091038406),\n",
       " (0.1304, 0.256, 0.35135135135135137, 0.39829302987197723),\n",
       " (0.0424, 0.148, 0.2930298719772404, 0.33001422475106684),\n",
       " (0.1952, 0.2952, 0.3413940256045519, 0.4167852062588905),\n",
       " (0.1376, 0.2976, 0.1379800853485064, 0.2034139402560455),\n",
       " (0.1192, 0.3192, 0.38264580369843526, 0.465149359886202),\n",
       " (0.064, 0.268, 0.21337126600284495, 0.3456614509246088),\n",
       " (0.1136, 0.3528, 0.07823613086770982, 0.2375533428165007),\n",
       " (0.7504, 0.9384, 1.0085348506401137, 1.0839260312944523),\n",
       " (0.2552, 0.3832, 0.37268847795163584, 0.41963015647226176),\n",
       " (1.0608, 1.464, 2.0825035561877665, 2.2859174964438123),\n",
       " (0.62, 0.9136, 1.372688477951636, 1.566145092460882),\n",
       " (0.2768, 0.3384, 0.2802275960170697, 0.31436699857752487),\n",
       " (0.2736, 0.3952, 0.3456614509246088, 0.4096728307254623),\n",
       " (0.0888, 0.256, 0.1891891891891892, 0.406827880512091),\n",
       " (0.2288, 0.3608, 0.30725462304409673, 0.3669985775248933),\n",
       " (0.4576, 0.6712, 0.6557610241820768, 0.7610241820768137),\n",
       " (0.1288, 0.2928, 0.29871977240398295, 0.35561877667140823),\n",
       " (0.0312, 0.1416, 0.28591749644381226, 0.3911806543385491),\n",
       " (0.1472, 0.2736, 0.3129445234708393, 0.3655761024182077),\n",
       " (0.1624, 0.2376, 0.30867709815078237, 0.3413940256045519),\n",
       " (0.0184, 0.3264, 0.2460881934566145, 0.5561877667140825),\n",
       " (0.5904, 0.8072, 0.930298719772404, 1.027027027027027),\n",
       " (0.1864, 0.3456, 0.1251778093883357, 0.2147937411095306),\n",
       " (0.1656, 0.2848, 0.24751066856330015, 0.40825035561877665),\n",
       " (0.0848, 0.196, 0.2233285917496444, 0.27880512091038406),\n",
       " (0.3352, 0.4104, 0.2460881934566145, 0.3029871977240398),\n",
       " (0.1312, 0.228, 0.14082503556187767, 0.19487908961593173),\n",
       " (0.7424, 0.9752, 0.7724039829302988, 0.8620199146514936),\n",
       " (0.636, 0.876, 1.0682788051209104, 1.1948790896159318),\n",
       " (0.0288, 0.372, 0.09103840682788052, 0.23897581792318634),\n",
       " (0.2192, 0.4016, 0.002844950213371266, 0.08392603129445235),\n",
       " (0.0904, 0.336, 0.2972972972972973, 0.36984352773826457),\n",
       " (0.6304, 1.22, 2.3826458036984355, 2.6330014224751066),\n",
       " (0.1568, 0.2816, 0.19203413940256045, 0.2460881934566145),\n",
       " (0.2376, 0.3376, 0.24751066856330015, 0.310099573257468),\n",
       " (0.2984, 0.4224, 0.5206258890469416, 0.5803698435277382),\n",
       " (0.0312, 0.0864, 0.18349928876244664, 0.2233285917496444),\n",
       " (0.1176, 0.2688, 0.24039829302987198, 0.2972972972972973),\n",
       " (0.212, 0.58, 0.35135135135135137, 0.49359886201991465),\n",
       " (0.2392, 0.3536, 0.4793741109530583, 0.5490753911806543),\n",
       " (0.3648, 0.5208, 1.027027027027027, 1.1066856330014225),\n",
       " (0.2648, 0.4304, 0.3741109530583215, 0.45092460881934565),\n",
       " (0.132, 0.2624, 0.39260312944523473, 0.46088193456614507),\n",
       " (0.1568, 0.3536, 0.3229018492176387, 0.4167852062588905),\n",
       " (0.2504, 0.304, 0.15789473684210525, 0.20056899004267426),\n",
       " (0.0504, 0.1944, 0.3328591749644381, 0.38975817923186346),\n",
       " (0.5008, 0.6144, 0.39829302987197723, 0.5106685633001422),\n",
       " (0.0752, 0.1648, 0.4366998577524893, 0.4751066856330014),\n",
       " (0.1256, 0.2632, 0.36984352773826457, 0.42105263157894735),\n",
       " (0.1064, 0.2232, 0.5007112375533428, 0.5476529160739687),\n",
       " (0.9904, 1.9744, 1.4395448079658606, 1.8051209103840682),\n",
       " (0.1408, 0.2408, 0.3015647226173542, 0.3385490753911807),\n",
       " (0.1488, 0.316, 0.534850640113798, 0.6116642958748222),\n",
       " (0.0528, 0.1232, 0.2361308677098151, 0.2802275960170697),\n",
       " (0.0976, 0.1792, 0.3812233285917496, 0.41536273115220484),\n",
       " (0.0008, 0.24, 0.13086770981507823, 0.21906116642958748),\n",
       " (0.3584, 0.5104, 0.3883357041251778, 0.48079658605974396),\n",
       " (0.2312, 0.3368, 0.267425320056899, 0.33001422475106684),\n",
       " (0.0808, 0.3176, 0.31721194879089615, 0.4139402560455192),\n",
       " (0.0392, 0.0848, 0.32716927453769556, 0.3541963015647226),\n",
       " (0.3392, 0.4904, 0.7795163584637269, 0.8406827880512091),\n",
       " (0.156, 0.3064, 0.45519203413940257, 0.5092460881934566),\n",
       " (0.116, 0.2504, 0.2375533428165007, 0.28591749644381226),\n",
       " (0.0152, 0.0752, 0.3541963015647226, 0.4466571834992888),\n",
       " (0.188, 0.2792, 0.45376955903271693, 0.5007112375533428),\n",
       " (0.12, 0.2784, 0.3627311522048364, 0.42105263157894735),\n",
       " (0.0528, 0.1392, 0.3328591749644381, 0.3684210526315789),\n",
       " (0.0464, 0.1768, 0.28165007112375534, 0.38549075391180654),\n",
       " (0.6864, 0.8976, 0.8691322901849218, 0.9615931721194879),\n",
       " (0.0968, 0.1944, 0.23186344238975817, 0.28165007112375534),\n",
       " (0.0992, 0.1672, 0.14509246088193456, 0.18492176386913228),\n",
       " (0.1184, 0.1912, 0.35561877667140823, 0.45519203413940257),\n",
       " (0.0704, 0.1728, 0.7211948790896159, 0.7908961593172119),\n",
       " (0.0832, 0.1672, 0.21763869132290184, 0.25889046941678523),\n",
       " (0.1048, 0.1672, 0.18349928876244664, 0.21763869132290184),\n",
       " (0.0192, 0.1136, 0.2972972972972973, 0.3485064011379801),\n",
       " (0.0584, 0.208, 0.5419630156472262, 0.6571834992887624),\n",
       " (0.3232, 0.468, 0.6102418207681366, 0.6657183499288762),\n",
       " (0.1136, 0.2384, 0.39971550497866287, 0.465149359886202),\n",
       " (0.1096, 0.2096, 0.3541963015647226, 0.41251778093883357),\n",
       " (0.1424, 0.3048, 0.1721194879089616, 0.2574679943100996),\n",
       " (0.276, 0.6784, 0.3442389758179232, 0.5917496443812233),\n",
       " (0.1488, 0.26, 0.25177809388335703, 0.3015647226173542),\n",
       " (0.3136, 0.4136, 0.22901849217638692, 0.3029871977240398),\n",
       " (0.2576, 0.3832, 0.24039829302987198, 0.2887624466571835),\n",
       " (0.5128, 0.7088, 0.7368421052631579, 0.8221906116642959),\n",
       " (0.1984, 0.3368, 0.1721194879089616, 0.24751066856330015),\n",
       " (0.1256, 0.232, 0.27453769559032715, 0.32574679943101),\n",
       " (0.1792, 0.2456, 0.22475106685633, 0.2603129445234708),\n",
       " (0.0104, 0.3552, 0.19487908961593173, 0.3840682788051209),\n",
       " (0.2864, 0.8248, 0.4182076813655761, 0.7681365576102418),\n",
       " (0.3208, 0.4744, 0.6486486486486487, 0.701280227596017),\n",
       " (0.1488, 0.2936, 0.19487908961593173, 0.33001422475106684),\n",
       " (0.2416, 0.3888, 0.37695590327169276, 0.4310099573257468),\n",
       " (0.4256, 0.6816, 0.9046941678520626, 1.004267425320057),\n",
       " (0.2488, 0.4048, 0.46088193456614507, 0.5263157894736842),\n",
       " (0.1336, 0.2216, 0.26884779516358465, 0.32147937411095306),\n",
       " (0.1488, 0.2992, 0.41251778093883357, 0.47652916073968704),\n",
       " (0.1912, 0.2776, 0.26600284495021337, 0.30014224751066854),\n",
       " (0.1016, 0.1464, 0.17354196301564723, 0.22190611664295876),\n",
       " (0.184, 0.2528, 0.2887624466571835, 0.3285917496443812),\n",
       " (0.1224, 0.2008, 0.27880512091038406, 0.30867709815078237),\n",
       " (0.144, 0.4472, 0.30725462304409673, 0.4466571834992888),\n",
       " (0.1208, 0.224, 0.27453769559032715, 0.3186344238975818),\n",
       " (0.3712, 0.4488, 0.406827880512091, 0.48933143669985774),\n",
       " (0.1728, 0.2744, 0.22048364153627312, 0.2702702702702703),\n",
       " (0.068, 0.2064, 0.5547652916073968, 0.6344238975817923),\n",
       " (0.1832, 1.1128, 0.2901849217638691, 0.9388335704125178),\n",
       " (0.8744, 1.1168, 0.9174964438122333, 1.0341394025604551),\n",
       " (0.2568, 0.4472, 0.5974395448079659, 0.6884779516358464),\n",
       " (0.5096, 0.672, 0.6600284495021337, 0.7809388335704125),\n",
       " (0.132, 0.2728, 0.18349928876244664, 0.24182076813655762),\n",
       " (0.268, 0.3616, 0.44523470839260315, 0.4879089615931721),\n",
       " (0.0776, 0.1832, 0.48079658605974396, 0.5376955903271693),\n",
       " (0.12, 0.3024, 0.30867709815078237, 0.38264580369843526),\n",
       " (0.3064, 0.3928, 0.3015647226173542, 0.352773826458037),\n",
       " (0.0592, 0.128, 0.2119487908961593, 0.24893314366998578),\n",
       " (0.6848, 0.9744, 0.9459459459459459, 1.0682788051209104),\n",
       " (0.1464, 0.2, 0.29160739687055476, 0.32574679943101),\n",
       " (0.1312, 0.2688, 0.23044096728307253, 0.2773826458036984),\n",
       " (0.0616, 0.16, 0.3285917496443812, 0.41251778093883357),\n",
       " (0.0528, 0.1392, 0.4295874822190612, 0.4722617354196302),\n",
       " (0.1048, 0.1496, 0.18492176386913228, 0.20483641536273114),\n",
       " (0.1704, 0.2712, 0.39829302987197723, 0.4366998577524893),\n",
       " (0.0848, 0.2104, 0.3385490753911807, 0.39260312944523473),\n",
       " (0.288, 0.4, 0.24324324324324326, 0.2930298719772404),\n",
       " (0.1592, 0.2192, 0.2887624466571835, 0.31436699857752487),\n",
       " (0.3944, 0.6864, 1.2588904694167853, 1.3755334281650071),\n",
       " (0.4696, 0.5688, 1.0810810810810811, 1.1834992887624467),\n",
       " (0.3984, 0.6368, 1.0369843527738265, 1.1578947368421053),\n",
       " (1.4432, 1.9944, 2.466571834992888, 2.6770981507823612),\n",
       " (0.2008, 0.4336, 0.43812233285917496, 0.5476529160739687),\n",
       " (0.1264, 0.28, 0.3584637268847795, 0.422475106685633),\n",
       " (0.064, 0.1912, 0.5177809388335705, 0.5718349928876245),\n",
       " (0.0184, 0.128, 0.3712660028449502, 0.4566145092460882),\n",
       " (0.2576, 0.5456, 0.4267425320056899, 0.5277382645803699),\n",
       " (0.184, 0.292, 0.267425320056899, 0.31152204836415365),\n",
       " (0.1432, 0.2776, 0.36415362731152207, 0.41251778093883357),\n",
       " (0.1616, 0.3088, 0.2702702702702703, 0.3229018492176387),\n",
       " (0.1272, 0.2824, 0.16358463726884778, 0.2460881934566145),\n",
       " (0.2888, 0.3992, 0.5419630156472262, 0.6145092460881935),\n",
       " (0.1304, 0.2984, 0.35988620199146515, 0.465149359886202),\n",
       " (0.7168, 1.2464, 1.1578947368421053, 1.3783783783783783),\n",
       " (0.1264, 0.3112, 0.18349928876244664, 0.27453769559032715),\n",
       " (0.14, 0.232, 0.32432432432432434, 0.3627311522048364),\n",
       " (0.0792, 0.1728, 0.5220483641536273, 0.6017069701280228),\n",
       " (0.2048, 0.3048, 0.3314366998577525, 0.3712660028449502),\n",
       " (0.1512, 0.2392, 0.23044096728307253, 0.267425320056899),\n",
       " (0.2728, 0.4856, 1.3570412517780939, 1.438122332859175),\n",
       " (0.168, 0.268, 0.41109530583214793, 0.4992887624466572),\n",
       " (0.252, 0.532, 0.6287339971550497, 0.7553342816500711),\n",
       " (0.1336, 0.3304, 0.2958748221906117, 0.3741109530583215),\n",
       " (0.1872, 0.3376, 0.3613086770981508, 0.4182076813655761),\n",
       " (0.2168, 0.3792, 0.7311522048364154, 0.7980085348506402),\n",
       " (0.288, 0.3472, 0.24751066856330015, 0.2773826458036984),\n",
       " (0.0856, 0.2048, 0.20910384068278806, 0.25604551920341395),\n",
       " (0.0904, 0.2216, 0.4096728307254623, 0.49359886201991465),\n",
       " (0.8464, 1.0808, 0.9388335704125178, 1.0753911806543386),\n",
       " (0.1312, 0.2176, 0.31721194879089615, 0.35135135135135137),\n",
       " (0.012, 0.16, 0.04694167852062589, 0.17923186344238975),\n",
       " (0.1144, 0.2696, 0.29871977240398295, 0.3613086770981508),\n",
       " (0.2536, 0.4544, 0.45376955903271693, 0.5647226173541963),\n",
       " (0.1256, 0.2728, 0.2802275960170697, 0.35135135135135137),\n",
       " (0.0856, 0.1608, 0.3755334281650071, 0.4096728307254623),\n",
       " (0.0904, 0.2056, 0.4011379800853485, 0.45803698435277385),\n",
       " (0.6296, 0.728, 0.6728307254623044, 0.7297297297297297),\n",
       " (0.1712, 0.268, 0.19630156472261737, 0.24039829302987198),\n",
       " (0.5176, 0.5888, 0.4722617354196302, 0.55049786628734),\n",
       " (0.4648, 0.56, 0.3883357041251778, 0.45376955903271693),\n",
       " (0.096, 0.1992, 0.22901849217638692, 0.28733997155049784),\n",
       " (0.6472, 0.8272, 0.34992887624466573, 0.41963015647226176),\n",
       " (0.1952, 0.3224, 0.31436699857752487, 0.3669985775248933),\n",
       " (0.612, 1.0064, 1.1678520625889046, 1.2873399715504978),\n",
       " (0.6504, 0.8536, 0.9459459459459459, 1.0298719772403984),\n",
       " (0.0952, 0.176, 0.11948790896159317, 0.15789473684210525),\n",
       " (0.3176, 0.516, 0.8392603129445235, 0.9118065433854907),\n",
       " (0.2408, 0.4032, 0.4992887624466572, 0.5718349928876245),\n",
       " (0.4656, 0.6824, 0.8847795163584637, 0.9829302987197724),\n",
       " (0.5568, 0.8488, 0.7766714082503556, 0.9630156472261735),\n",
       " (0.096, 0.1472, 0.1465149359886202, 0.18492176386913228),\n",
       " (0.1464, 0.1992, 0.30014224751066854, 0.3229018492176387),\n",
       " (0.1664, 0.296, 0.12660028449502134, 0.2460881934566145),\n",
       " (0.0552, 0.468, 0.112375533428165, 0.2603129445234708),\n",
       " (0.1288, 0.2504, 0.3015647226173542, 0.3684210526315789),\n",
       " (0.7808, 1.0272, 0.9516358463726885, 1.0725462304409672),\n",
       " (0.116, 0.2552, 0.2844950213371266, 0.34708392603129445),\n",
       " (0.1456, 0.2792, 0.3385490753911807, 0.3883357041251778),\n",
       " (0.1136, 0.2744, 0.35988620199146515, 0.43243243243243246),\n",
       " (0.1736, 0.3424, 0.20910384068278806, 0.267425320056899),\n",
       " (0.1312, 0.2528, 0.30725462304409673, 0.3456614509246088),\n",
       " (0.3632, 0.6376, 0.155049786628734, 0.3328591749644381),\n",
       " (0.9192, 1.0864, 0.9231863442389758, 0.9985775248933144),\n",
       " (0.7096, 0.9384, 0.8890469416785206, 0.9900426742532006),\n",
       " (0.1152, 0.2216, 0.30725462304409673, 0.3584637268847795),\n",
       " (0.2304, 0.3432, 0.352773826458037, 0.39971550497866287),\n",
       " (0.0792, 0.1784, 0.02844950213371266, 0.07112375533428165),\n",
       " (0.3728, 0.592, 0.9672830725462305, 1.0483641536273116),\n",
       " (0.1768, 0.344, 0.2702702702702703, 0.3285917496443812),\n",
       " (0.0352, 0.5248, 0.18207681365576103, 0.5561877667140825),\n",
       " (0.4608, 0.7216, 0.6927453769559033, 0.8477951635846372),\n",
       " (0.1176, 0.296, 0.1891891891891892, 0.26173541963015645),\n",
       " (0.308, 0.5968, 0.4167852062588905, 0.6173541963015647),\n",
       " (0.2888, 0.4528, 0.2702702702702703, 0.422475106685633),\n",
       " (0.1096, 0.2816, 0.20056899004267426, 0.26458036984352773),\n",
       " (0.1248, 0.268, 0.3684210526315789, 0.4310099573257468),\n",
       " (0.1304, 0.2416, 0.5078236130867709, 0.6073968705547653),\n",
       " (0.1536, 0.2912, 0.3968705547652916, 0.45376955903271693),\n",
       " (0.2624, 0.464, 0.2958748221906117, 0.3613086770981508),\n",
       " (0.0248, 0.1112, 0.18207681365576103, 0.22901849217638692),\n",
       " (0.1984, 0.2976, 0.16500711237553342, 0.20483641536273114),\n",
       " (0.8192, 1.0184, 0.8691322901849218, 0.9672830725462305),\n",
       " (0.1056, 0.188, 0.24039829302987198, 0.27453769559032715),\n",
       " (0.2168, 0.3872, 0.4722617354196302, 0.5462304409672831),\n",
       " (0.092, 0.4192, 0.20483641536273114, 0.42105263157894735),\n",
       " (0.1584, 0.2792, 0.15220483641536273, 0.2034139402560455),\n",
       " (0.4504, 0.54, 0.29445234708392604, 0.3385490753911807)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c3bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data,dtype=np.float32)\n",
    "y = np.array(output,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24be4cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((225, 224, 224, 3), (225, 4))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc8a337e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180, 224, 224, 3), (45, 224, 224, 3), (180, 4), (45, 4))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.8,random_state=0)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54609e9f",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633506d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2, InceptionResNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "908c7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_resnet = InceptionResNetV2(weights=\"imagenet\",include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
    "inception_resnet.trainable = False\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "headmodel = inception_resnet.output\n",
    "headmodel = Flatten()(headmodel)\n",
    "headmodel = Dense(500,activation=\"relu\")(headmodel)\n",
    "headmodel = Dense(250,activation=\"relu\")(headmodel)\n",
    "headmodel = Dense(4,activation='sigmoid')(headmodel)\n",
    "#-----------------------------------------Model\n",
    "model = Model(inception_resnet.input,outputs=headmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a9426bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 96)   18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 64)   12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 96)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 96)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 25, 25, 320)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 48)   13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 48)   144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 64)   27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 25, 25, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 25, 25, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 48)   13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 32)   9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 32)   96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 32)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 25, 25, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 25, 25, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 48)   13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 48)   144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 48)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 32)   9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 64)   27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 64)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 25, 25, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 25, 25, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 25, 25, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 25, 25, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 25, 25, 48)   13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 25, 25, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 25, 25, 48)   144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 25, 25, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 25, 25, 48)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 25, 25, 32)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 25, 25, 64)   27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 25, 25, 32)   96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 25, 25, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 25, 25, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 25, 25, 32)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 25, 25, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 25, 25, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 25, 25, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 25, 25, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 25, 25, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 25, 25, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 25, 25, 48)   13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 25, 25, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 25, 25, 48)   144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 25, 25, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 25, 25, 48)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 25, 25, 32)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 25, 25, 64)   27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 25, 25, 32)   96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 25, 25, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 25, 25, 64)   192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 25, 25, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 25, 25, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 25, 25, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 25, 25, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 25, 25, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 25, 25, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 25, 25, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 25, 25, 48)   13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 25, 25, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 25, 25, 48)   144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 25, 25, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 25, 25, 48)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 25, 25, 32)   9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 25, 25, 64)   27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 25, 25, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 25, 25, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 25, 25, 64)   192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 25, 25, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 25, 25, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 25, 25, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 25, 25, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 25, 25, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 25, 25, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 25, 25, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 25, 25, 48)   13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 25, 25, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 25, 25, 48)   144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 25, 25, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 25, 25, 48)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 25, 25, 32)   9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 25, 25, 64)   27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 25, 25, 32)   96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 25, 25, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 25, 25, 64)   192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 25, 25, 32)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 25, 25, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 25, 25, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 25, 25, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 25, 25, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 25, 25, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 25, 25, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 25, 25, 48)   13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 25, 25, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 25, 25, 48)   144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 25, 25, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 25, 25, 48)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 25, 25, 32)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 25, 25, 64)   27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 25, 25, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 25, 25, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 25, 25, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 25, 25, 32)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 25, 25, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 25, 25, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 25, 25, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 25, 25, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 25, 25, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 25, 25, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 25, 25, 48)   13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 25, 25, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 25, 25, 48)   144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 25, 25, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 25, 25, 48)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 25, 25, 32)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 25, 25, 64)   27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 25, 25, 32)   96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 25, 25, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 25, 25, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 25, 25, 32)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 25, 25, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 25, 25, 64)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 25, 25, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 25, 25, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 25, 25, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 25, 25, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 25, 25, 48)   13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 25, 25, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 25, 25, 48)   144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 25, 25, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 25, 25, 48)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 25, 25, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 25, 25, 64)   27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 25, 25, 32)   96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 25, 25, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 25, 25, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 25, 25, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 25, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 25, 25, 64)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 25, 25, 128)  0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 25, 25, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 25, 25, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 25, 25, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 25, 25, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 25, 25, 256)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 25, 25, 256)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 25, 25, 256)  589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 25, 25, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 25, 25, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 384)  884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 384)  1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 384)  1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 384)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 384)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 12, 12, 1088) 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 12, 12, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 12, 12, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 12, 12, 128)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 12, 12, 160)  143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 12, 12, 160)  480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 12, 12, 160)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 12, 12, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 12, 12, 192)  215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 12, 12, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 12, 12, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 12, 12, 192)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 12, 12, 192)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 12, 12, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 12, 12, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 12, 12, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 12, 12, 128)  384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 12, 12, 128)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 12, 12, 160)  143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 12, 12, 160)  480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 12, 12, 160)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 12, 12, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 12, 12, 192)  215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 12, 12, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 12, 12, 192)  576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 12, 12, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 12, 12, 192)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 12, 12, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 12, 12, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 12, 12, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 12, 12, 128)  384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 12, 12, 128)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 12, 12, 160)  143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 12, 12, 160)  480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 12, 12, 160)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 12, 12, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 12, 12, 192)  215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 12, 12, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 12, 12, 192)  576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 12, 12, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 12, 12, 192)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 12, 12, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 12, 12, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 12, 12, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 12, 12, 128)  384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 12, 12, 128)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 12, 12, 160)  143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 12, 12, 160)  480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 12, 12, 160)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 12, 12, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 12, 12, 192)  215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 12, 12, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 12, 12, 192)  576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 12, 12, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 12, 12, 192)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 12, 12, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 12, 12, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 12, 12, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 12, 12, 128)  384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 12, 12, 128)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 12, 12, 160)  143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 12, 12, 160)  480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 12, 12, 160)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 12, 12, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 12, 12, 192)  215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 12, 12, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 12, 12, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 12, 12, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 12, 12, 192)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 12, 12, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 12, 12, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 12, 12, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 12, 12, 128)  384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 12, 12, 128)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 12, 12, 160)  143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 12, 12, 160)  480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 12, 12, 160)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 12, 12, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 12, 12, 192)  215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 12, 12, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 12, 12, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 12, 12, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 12, 12, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 12, 12, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 12, 12, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 12, 12, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 12, 12, 128)  384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 12, 12, 128)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 12, 12, 160)  143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 12, 12, 160)  480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 12, 12, 160)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 12, 12, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 12, 12, 192)  215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 12, 12, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 12, 12, 192)  576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 12, 12, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 12, 12, 192)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 12, 12, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 12, 12, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 12, 12, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 12, 12, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 12, 12, 128)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 12, 12, 160)  143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 12, 12, 160)  480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 12, 12, 160)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 12, 12, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 12, 12, 192)  215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 12, 12, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 12, 12, 192)  576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 12, 12, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 12, 12, 192)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 12, 12, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 12, 12, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 12, 12, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 12, 12, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 12, 12, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 12, 12, 160)  143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 12, 12, 160)  480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 12, 12, 160)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 12, 12, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 12, 12, 192)  215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 12, 12, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 12, 12, 192)  576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 12, 12, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 12, 12, 192)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 12, 12, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 12, 12, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 12, 12, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 12, 12, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 12, 12, 128)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 12, 12, 160)  143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 12, 12, 160)  480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 12, 12, 160)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 12, 12, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 12, 12, 192)  215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 12, 12, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 12, 12, 192)  576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 12, 12, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 12, 12, 192)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 12, 12, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 12, 12, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 12, 12, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 12, 12, 128)  384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 12, 12, 128)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 12, 12, 160)  143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 12, 12, 160)  480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 12, 12, 160)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 12, 12, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 12, 12, 192)  215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 12, 12, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 12, 12, 192)  576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 12, 12, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 12, 12, 192)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 12, 12, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 12, 12, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 12, 12, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 12, 12, 128)  384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 12, 12, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 12, 12, 160)  143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 12, 12, 160)  480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 12, 12, 160)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 12, 12, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 12, 12, 192)  215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 12, 12, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 12, 12, 192)  576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 12, 12, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 12, 12, 192)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 12, 12, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 12, 12, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 12, 12, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 12, 12, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 12, 12, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 12, 12, 160)  143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 12, 12, 160)  480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 12, 12, 160)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 12, 12, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 12, 12, 192)  215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 12, 12, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 12, 12, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 12, 12, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 12, 12, 192)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 12, 12, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 12, 12, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 12, 12, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 12, 12, 160)  143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 12, 12, 160)  480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 12, 12, 160)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 12, 12, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 12, 12, 192)  215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 12, 12, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 12, 12, 192)  576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 12, 12, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 12, 12, 192)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 12, 12, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 12, 12, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 12, 12, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 12, 12, 128)  384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 12, 12, 128)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 12, 12, 160)  143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 12, 12, 160)  480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 12, 12, 160)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 12, 12, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 12, 12, 192)  215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 12, 12, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 12, 12, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 12, 12, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 12, 12, 192)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 12, 12, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 12, 12, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 12, 12, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 12, 12, 128)  384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 12, 12, 128)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 12, 12, 160)  143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 12, 12, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 12, 12, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 12, 12, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 12, 12, 192)  215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 12, 12, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 12, 12, 192)  576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 12, 12, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 12, 12, 192)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 12, 12, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 12, 12, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 12, 12, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 12, 12, 128)  384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 12, 12, 128)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 12, 12, 160)  143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 12, 12, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 12, 12, 160)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 12, 12, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 12, 12, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 12, 12, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 12, 12, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 12, 12, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 12, 12, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 12, 12, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 12, 12, 128)  384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 12, 12, 128)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 12, 12, 160)  143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 12, 12, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 12, 12, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 12, 12, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 12, 12, 192)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 12, 12, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 12, 12, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 12, 12, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 12, 12, 128)  384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 12, 12, 128)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 12, 12, 160)  143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 12, 12, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 12, 12, 192)  215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 12, 12, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 12, 12, 192)  576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 12, 12, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 12, 12, 192)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 12, 12, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 12, 12, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 12, 12, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 12, 12, 128)  384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 12, 12, 128)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 12, 12, 160)  143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 12, 12, 160)  480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 12, 12, 160)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 12, 12, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 12, 12, 192)  215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 12, 12, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 12, 12, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 12, 12, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 12, 12, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 12, 12, 256)  768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 12, 12, 256)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 12, 12, 288)  663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 12, 12, 256)  768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 12, 12, 256)  768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 12, 12, 288)  864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 12, 12, 256)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 12, 12, 256)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 12, 288)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 5, 5, 384)    884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 5, 5, 288)    663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 5, 5, 320)    829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 5, 5, 384)    1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 5, 5, 288)    864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 5, 5, 320)    960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 5, 5, 384)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 5, 5, 288)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 5, 5, 320)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 5, 5, 2080)   0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 5, 5, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 5, 5, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 5, 5, 224)    129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 5, 5, 224)    672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 5, 5, 224)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 5, 5, 256)    172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 5, 5, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 5, 5, 256)    768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 5, 5, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 5, 5, 256)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 5, 5, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 5, 5, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 5, 5, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 5, 5, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 5, 5, 224)    129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 5, 5, 224)    672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 5, 5, 224)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 5, 5, 256)    172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 5, 5, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 5, 5, 256)    768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 5, 5, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 5, 5, 256)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 5, 5, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 5, 5, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 5, 5, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 5, 5, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 5, 5, 224)    129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 5, 5, 224)    672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 5, 5, 224)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 5, 5, 256)    172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 5, 5, 192)    576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 5, 5, 256)    768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 5, 5, 192)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 5, 5, 256)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 5, 5, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 5, 5, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 5, 5, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 5, 5, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 5, 5, 224)    129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 5, 5, 224)    672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 5, 5, 224)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 5, 5, 256)    172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 5, 5, 192)    576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 5, 5, 256)    768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 5, 5, 192)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 5, 5, 256)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 5, 5, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 5, 5, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 5, 5, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 5, 5, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 5, 5, 224)    129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 5, 5, 224)    672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_181 (Activation)     (None, 5, 5, 224)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 5, 5, 256)    172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 5, 5, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 5, 5, 256)    768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 5, 5, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 5, 5, 256)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 5, 5, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 5, 5, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 5, 5, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 5, 5, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 5, 5, 224)    129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 5, 5, 224)    672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 5, 5, 224)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 5, 5, 256)    172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 5, 5, 192)    576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 5, 5, 256)    768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 5, 5, 192)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 5, 5, 256)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 5, 5, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 5, 5, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 5, 5, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 5, 5, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 5, 5, 224)    129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 5, 5, 224)    672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 5, 5, 224)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 5, 5, 256)    172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 5, 5, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 5, 5, 256)    768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 5, 5, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 5, 5, 256)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 5, 5, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 5, 5, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 5, 5, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 5, 5, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 5, 5, 224)    129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 5, 5, 224)    672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 5, 5, 224)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 5, 5, 256)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 5, 5, 192)    576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 5, 5, 256)    768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 5, 5, 192)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 5, 5, 256)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 5, 5, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 5, 5, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 5, 5, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 5, 5, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 5, 5, 224)    129024      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 5, 5, 224)    672         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 5, 5, 224)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 5, 5, 256)    172032      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 5, 5, 192)    576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 5, 5, 256)    768         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 5, 5, 192)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 5, 5, 256)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 5, 5, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 5, 5, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 5, 5, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 5, 5, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 5, 5, 224)    129024      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 5, 5, 224)    672         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 5, 5, 224)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 5, 5, 256)    172032      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 5, 5, 192)    576         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 5, 5, 256)    768         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 5, 5, 192)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 5, 5, 256)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 5, 5, 448)    0           activation_199[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 5, 5, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 5, 5, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 5, 5, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 5, 5, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 5, 5, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 38400)        0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          19200500    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 250)          125250      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            1004        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 73,663,490\n",
      "Trainable params: 19,326,754\n",
      "Non-trainable params: 54,336,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c03c9",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f483956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dfb9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfb = TensorBoard('object_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bee2fefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.3364 - val_loss: 0.4146\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3717 - val_loss: 0.4146\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.3551 - val_loss: 0.4146\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.3257 - val_loss: 0.4146\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.3260 - val_loss: 0.4146\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.3344 - val_loss: 0.4146\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.3326 - val_loss: 0.4146\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3339 - val_loss: 0.4146\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.3260 - val_loss: 0.4146\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3306 - val_loss: 0.4146\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3284 - val_loss: 0.4146\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3257 - val_loss: 0.4146\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.3313 - val_loss: 0.4146\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3333 - val_loss: 0.4146\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3315 - val_loss: 0.4146\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3352 - val_loss: 0.4146\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.3358 - val_loss: 0.4146\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.3230 - val_loss: 0.4146\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.3272 - val_loss: 0.4146\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.3331 - val_loss: 0.4146\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.3302 - val_loss: 0.4146\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.3284 - val_loss: 0.4146\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.3410 - val_loss: 0.4146\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.3177 - val_loss: 0.4146\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.3223 - val_loss: 0.4146\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.3260 - val_loss: 0.4146\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.3267 - val_loss: 0.4146\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.3232 - val_loss: 0.4146\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.3381 - val_loss: 0.4146\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.3215 - val_loss: 0.4146\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.3372 - val_loss: 0.4146\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.3133 - val_loss: 0.4146\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.3347 - val_loss: 0.4146\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.3595 - val_loss: 0.4146\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.3392 - val_loss: 0.4146\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.3472 - val_loss: 0.4146\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.3238 - val_loss: 0.4146\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.3679 - val_loss: 0.4146\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3279 - val_loss: 0.4146\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3202 - val_loss: 0.4146\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 31s 2s/step - loss: 0.3301 - val_loss: 0.4146\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 31s 2s/step - loss: 0.3329 - val_loss: 0.4146\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3224 - val_loss: 0.4146\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3251 - val_loss: 0.4146\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3315 - val_loss: 0.4146\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3510 - val_loss: 0.4146\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3241 - val_loss: 0.4146\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3271 - val_loss: 0.4146\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3535 - val_loss: 0.4146\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3365 - val_loss: 0.4146\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3218 - val_loss: 0.4146\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 33s 2s/step - loss: 0.3296 - val_loss: 0.4146\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.3342 - val_loss: 0.4146\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3294 - val_loss: 0.4146\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.3319 - val_loss: 0.4146\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.3231 - val_loss: 0.4146\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.3293 - val_loss: 0.4146\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.3498 - val_loss: 0.4146\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.3242 - val_loss: 0.4146\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.3223 - val_loss: 0.4146\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3340 - val_loss: 0.4146\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3523 - val_loss: 0.4146\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3600 - val_loss: 0.4146\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3566 - val_loss: 0.4146\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3264 - val_loss: 0.4146\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3487 - val_loss: 0.4146\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3406 - val_loss: 0.4146\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3312 - val_loss: 0.4146\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3484 - val_loss: 0.4146\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3395 - val_loss: 0.4146\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3198 - val_loss: 0.4146\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3322 - val_loss: 0.4146\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3560 - val_loss: 0.4146\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3240 - val_loss: 0.4146\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3541 - val_loss: 0.4146\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3531 - val_loss: 0.4146\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3290 - val_loss: 0.4146\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3475 - val_loss: 0.4146\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3623 - val_loss: 0.4146\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3476 - val_loss: 0.4146\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3343 - val_loss: 0.4146\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3303 - val_loss: 0.4146\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 21s 1s/step - loss: 0.3572 - val_loss: 0.4146\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3390 - val_loss: 0.4146\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3447 - val_loss: 0.4146\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3201 - val_loss: 0.4146\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3358 - val_loss: 0.4146\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3348 - val_loss: 0.4146\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3249 - val_loss: 0.4146\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3590 - val_loss: 0.4146\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3582 - val_loss: 0.4146\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3208 - val_loss: 0.4146\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3544 - val_loss: 0.4146\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3578 - val_loss: 0.4146\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3388 - val_loss: 0.4146\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3332 - val_loss: 0.4146\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3336 - val_loss: 0.4146\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3271 - val_loss: 0.4146\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3197 - val_loss: 0.4146\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3322 - val_loss: 0.4146\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train,y=y_train,batch_size=10,epochs=100,\n",
    "                   validation_data=(x_test,y_test),callbacks=[tfb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a67120d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3321 - val_loss: 0.4146\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train,y=y_train,batch_size=10,epochs=200,\n",
    "                   validation_data=(x_test,y_test),callbacks=[tfb],initial_epoch=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaa14042",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/mothikaa/ANPR/models/object_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6fc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
